'''
FACE ORIENTATION DETECTION USING MACHINE LEARNING


Program description:
1. The training data is generated by extracting patches from the training images and randomly rotating them by 90 degrees. The multiple of 90 is stored as the label.
2. Training image classifiers for 3 different patch sizes. The Multi-layer Perceptron (MLP) classifier is used with Prinicipal Component Analysis (PCA)
for dimensionality reduction.
3. The hyperparameters are manually tuned for each values of the patch sizes. The trained models are saved in the models folder.


Username: ACP23SD
Date: 15/12/2023
Course ID: COM6018 - Data Science with Python - Assignment -2

'''


############################################################################################################

# Importing the libraries

import joblib
import numpy as np
from sklearn.feature_extraction import image

from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPClassifier


############################################################################################################


# Data preparation function

np.random.seed(42)

def prep_data(filePath,size,patches=5):

    # Image extraction phase
    images, _ = joblib.load(filePath)
    patch_extractor = image.PatchExtractor(patch_size=(size, size), max_patches=patches, random_state=42)
    sub_images = patch_extractor.transform(images)


    # Random 90-degree rotation phase
    sub_images_rot = np.zeros(sub_images.shape)

    labels = np.zeros(sub_images.shape[0])
    for i in range(sub_images.shape[0]):
        random_k = np.random.randint(0, 4)
        labels[i] = random_k
        sub_images_rot[i] = np.rot90(sub_images[i], k=random_k, axes=(0, 1))

    # Feature representation phase

    features = sub_images_rot.reshape(len(sub_images), -1)
    dataset = {'features': features, 'labels': labels}
    return dataset


filePath = 'data/train.full.joblib'
patches = 5


############################################################################################################

# Pixel size 90

# Data preparation
size90 = 90
train_data_90 = prep_data(filePath,size90,patches)


# Machine Learning Pipeline - PCA + MLP
pca_90 = PCA(n_components=90)
mlp_90 = MLPClassifier(activation='relu',alpha=0.1,hidden_layer_sizes=(100))
model90 = Pipeline([('pca', pca_90), ('mlp', mlp_90)])

# Training and saving the model
model90.fit(train_data_90['features'], train_data_90['labels'])
joblib.dump(model90, 'models/model90.joblib')


############################################################################################################

# Pixel size 50

# Data preparation
size50 = 50
train_data_50 = prep_data(filePath,size50,patches)

# Machine Learning Pipeline - PCA + MLP
pca_50 = PCA(n_components=50)
mlp_50 = MLPClassifier(activation='tanh',alpha=0.1,hidden_layer_sizes=(200,200),max_iter=500)
model50 = Pipeline([('pca', pca_50), ('mlp', mlp_50)])

# Training and saving the model
model50.fit(train_data_50['features'], train_data_50['labels'])
joblib.dump(model50, 'models/model50.joblib')

############################################################################################################

# Pixel size 30

# Data preparation
size30 = 30
train_data_30 = prep_data(filePath,size30,patches)

# Machine Learning Pipeline - PCA + MLP
pca_30 = PCA(n_components=30)
mlp_30 = MLPClassifier(activation='tanh',alpha=0.1,hidden_layer_sizes=(200,200),max_iter=1000)
model30 = Pipeline([('pca', pca_30), ('mlp', mlp_30)])

# Training and saving the model
model30.fit(train_data_30['features'], train_data_30['labels'])
joblib.dump(model30, 'models/model30.joblib')


############################################################################################################